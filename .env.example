# NVIDIA GPU Requirements Analyzer - Web Interface Configuration
# Copy this file to .env and customize the values as needed

# Basic Application Settings
DEBUG=false
SECRET_KEY=your-production-secret-key-here

# LLM Enhancement (Optional)
# Uncomment and configure these to enable enhanced analysis with LLM
# OPENAI_BASE_URL=https://integrate.api.nvidia.com/v1
# OPENAI_API_KEY=your-api-key-here
# OPENAI_MODEL=nvidia/llama-3.1-nemotron-ultra-253b-v1

# Alternative: Use OpenAI directly
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_API_KEY=sk-your-openai-key
# OPENAI_MODEL=gpt-4

# Alternative: Use local LLM (e.g., Ollama)
# OPENAI_BASE_URL=http://host.docker.internal:11434/v1
# OPENAI_API_KEY=dummy
# OPENAI_MODEL=llama3:8b

# Repository Access Tokens (Optional)
# Uncomment these to enable analysis of private repositories
# GITHUB_TOKEN=ghp_your_personal_access_token
# GITLAB_TOKEN=glpat_your_personal_access_token

# Note: Environment variables can also be set in your shell instead of using this file
# Example: export OPENAI_API_KEY="your-key" && docker compose up
